{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOBy2fhOaQ7kQaqfUzpwGkg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Pratikshya49/Concepts-and-Technologies-of-AI/blob/main/Worksheet6_part_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1. Logistic (Sigmoid) Function**\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "NGacu-ufchlO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def logistic_function(x):\n",
        "    \"\"\"\n",
        "    Computes the logistic (sigmoid) function.\n",
        "    \"\"\"\n",
        "    return 1 / (1 + np.exp(-x))\n"
      ],
      "metadata": {
        "id": "kvs6bjtTcmD9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_logistic_function():\n",
        "    x_scalar = 0\n",
        "    assert round(logistic_function(x_scalar), 3) == 0.5\n",
        "\n",
        "    x_pos = 2\n",
        "    assert round(logistic_function(x_pos), 3) == round(1 / (1 + np.exp(-2)), 3)\n",
        "\n",
        "    x_neg = -3\n",
        "    assert round(logistic_function(x_neg), 3) == round(1 / (1 + np.exp(3)), 3)\n",
        "\n",
        "    x_array = np.array([0, 2, -3])\n",
        "    expected = np.array([0.5, 0.881, 0.047])\n",
        "    assert np.all(np.round(logistic_function(x_array), 3) == expected)\n",
        "\n",
        "    print(\"All tests passed!\")\n",
        "\n",
        "test_logistic_function()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TZ3Jqbi1cvfD",
        "outputId": "0280fb90-66ec-4f56-bf9a-f63a99c53b8f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All tests passed!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Log-Loss **Function** **bold text** bold text"
      ],
      "metadata": {
        "id": "7IsZjwRrcxtx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def log_loss(y_true, y_pred):\n",
        "    import numpy as np\n",
        "\n",
        "    y_pred = np.clip(y_pred, 1e-10, 1 - 1e-10)\n",
        "    loss = -(y_true * np.log(y_pred)) - ((1 - y_true) * np.log(1 - y_pred))\n",
        "    return loss\n"
      ],
      "metadata": {
        "id": "3DwK4oabc4Os"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_log_loss():\n",
        "    import numpy as np\n",
        "\n",
        "    assert np.isclose(log_loss(1, 1), 0.0)\n",
        "    assert np.isclose(log_loss(0, 0), 0.0)\n",
        "\n",
        "    y_true, y_pred = 1, 0.8\n",
        "    expected = -np.log(0.8)\n",
        "    assert np.isclose(log_loss(y_true, y_pred), expected)\n",
        "\n",
        "    y_true, y_pred = 0, 0.2\n",
        "    expected = -np.log(0.8)\n",
        "    assert np.isclose(log_loss(y_true, y_pred), expected)\n",
        "\n",
        "    print(\"All tests passed!\")\n",
        "\n",
        "test_log_loss()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sINy_QBKc6dJ",
        "outputId": "493a9d08-fd89-42a9-e4ff-a4d9f9b3f9a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All tests passed!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3. Cost Function (Average Log-Loss)**"
      ],
      "metadata": {
        "id": "pmloM3Enc948"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def cost_function(y_true, y_pred):\n",
        "    assert len(y_true) == len(y_pred)\n",
        "\n",
        "    n = len(y_true)\n",
        "    loss_vec = log_loss(y_true, y_pred)\n",
        "    cost = np.sum(loss_vec) / n\n",
        "    return cost\n"
      ],
      "metadata": {
        "id": "w_N7eoQadAgH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_cost_function():\n",
        "    import numpy as np\n",
        "\n",
        "    y_true = np.array([1, 0, 1])\n",
        "    y_pred = np.array([0.9, 0.1, 0.8])\n",
        "\n",
        "    expected_cost = (\n",
        "        -np.log(0.9) - np.log(0.9) - np.log(0.8)\n",
        "    ) / 3\n",
        "\n",
        "    result = cost_function(y_true, y_pred)\n",
        "    assert np.isclose(result, expected_cost, atol=1e-6)\n",
        "\n",
        "    print(\"Test passed!\")\n",
        "\n",
        "test_cost_function()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zdifibSgdCty",
        "outputId": "338cdafe-e364-4f2f-8846-d125beab5603"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test passed!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4.Vectorized Cost Function (Using Parameters)**"
      ],
      "metadata": {
        "id": "hl2WYVxddExT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def costfunction_logreg(X, y, w, b):\n",
        "    n, d = X.shape\n",
        "\n",
        "    z = np.dot(X, w) + b\n",
        "    y_pred = logistic_function(z)\n",
        "    cost = cost_function(y, y_pred)\n",
        "    return cost\n"
      ],
      "metadata": {
        "id": "YqO4Y70gdIfb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.array([[10, 20], [-10, 10]])\n",
        "y = np.array([1, 0])\n",
        "w = np.array([0.5, 1.5])\n",
        "b = 1\n",
        "\n",
        "print(costfunction_logreg(X, y, w, b))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zOM6AP-hdKdW",
        "outputId": "a65b9b17-362e-4b38-e7ba-a72955a86b53"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5.500008350834906\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**5. Gradient Computation**"
      ],
      "metadata": {
        "id": "G77TF1c_dOPn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_gradient(X, y, w, b):\n",
        "    n, d = X.shape\n",
        "\n",
        "    z = np.dot(X, w) + b\n",
        "    y_pred = logistic_function(z)\n",
        "\n",
        "    error = y_pred - y\n",
        "    grad_w = (1 / n) * np.dot(X.T, error)\n",
        "    grad_b = (1 / n) * np.sum(error)\n",
        "\n",
        "    return grad_w, grad_b\n"
      ],
      "metadata": {
        "id": "R0hdF2gjdPwr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "X = np.array([[10, 20], [-10, 10]])\n",
        "y = np.array([1, 0])\n",
        "w = np.array([0.5, 1.5])\n",
        "b = 1\n",
        "# Assertion tests\n",
        "try:\n",
        "    grad_w, grad_b = compute_gradient(X, y, w, b)\n",
        "    print(\"Gradients computed successfully.\")\n",
        "    print(f\"grad_w: {grad_w}\")\n",
        "    print(f\"grad_b: {grad_b}\")\n",
        "except AssertionError as e:\n",
        "    print(f\"Assertion error: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vbx4kYM7f914",
        "outputId": "ba7f1c3e-48e6-4a61-cf44-ab3650d124c9"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gradients computed successfully.\n",
            "grad_w: [-4.99991649  4.99991649]\n",
            "grad_b: 0.4999916492890759\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**6. Gradient Descent**"
      ],
      "metadata": {
        "id": "TDkN43ZwdV5Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def gradient_descent(X, y, w, b, alpha, n_iter, show_cost=False, show_params=True):\n",
        "    cost_history = []\n",
        "    params_history = []\n",
        "\n",
        "    for i in range(n_iter):\n",
        "        grad_w, grad_b = compute_gradient(X, y, w, b)\n",
        "\n",
        "        w -= alpha * grad_w\n",
        "        b -= alpha * grad_b\n",
        "\n",
        "        cost = costfunction_logreg(X, y, w, b)\n",
        "\n",
        "        cost_history.append(cost)\n",
        "        params_history.append((w.copy(), b))\n",
        "\n",
        "        if show_cost and (i % 100 == 0 or i == n_iter - 1):\n",
        "            print(f\"Iteration {i}: Cost = {cost:.6f}\")\n",
        "        if show_params and (i % 100 == 0 or i == n_iter - 1):\n",
        "            print(f\"Iteration {i}: w = {w}, b = {b:.6f}\")\n",
        "\n",
        "    return w, b, cost_history, params_history\n"
      ],
      "metadata": {
        "id": "YXQSP4WKdXCb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_gradient_descent():\n",
        "    X = np.array([[0.1, 0.2], [-0.1, 0.1]])\n",
        "    y = np.array([1, 0])\n",
        "    w = np.zeros(2)\n",
        "    b = 0.0\n",
        "\n",
        "    w_out, b_out, cost_history, _ = gradient_descent(X, y, w, b, 0.1, 100)\n",
        "\n",
        "    assert len(cost_history) == 100\n",
        "    assert cost_history[-1] < cost_history[0]\n",
        "    print(\"All tests passed!\")\n",
        "\n",
        "test_gradient_descent()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KgWGu6EodaE1",
        "outputId": "ef5fc80e-383e-4ecb-e241-6f23e6a3e3fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 0: w = [0.005  0.0025], b = 0.000000\n",
            "Iteration 99: w = [0.49236201 0.24271295], b = -0.023120\n",
            "All tests passed!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**7. Prediction Function**"
      ],
      "metadata": {
        "id": "QfbzMa_jdc4h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def prediction(X, w, b, threshold=0.5):\n",
        "    z = np.dot(X, w) + b\n",
        "    y_prob = logistic_function(z)\n",
        "    y_pred = (y_prob >= threshold).astype(int)\n",
        "    return y_pred"
      ],
      "metadata": {
        "id": "t6eUZfxOdeIu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_prediction():\n",
        "    X = np.array([[0.5, 1.0], [1.5, -0.5], [-0.5, -1.0]])\n",
        "    w = np.array([1.0, -1.0])\n",
        "    b = 0.0\n",
        "\n",
        "    expected = np.array([0, 1, 1])\n",
        "    assert np.array_equal(prediction(X, w, b), expected)\n",
        "\n",
        "    print(\"Test passed!\")\n",
        "\n",
        "test_prediction()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B6f-XCsrdf1D",
        "outputId": "6efdc888-6d42-4c6a-a2b6-52f951dd4bc0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test passed!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**8. Evaluation Metrics**"
      ],
      "metadata": {
        "id": "VjL52pSvdjPs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_classification(y_true, y_pred):\n",
        "    TP = np.sum((y_true == 1) & (y_pred == 1))\n",
        "    TN = np.sum((y_true == 0) & (y_pred == 0))\n",
        "    FP = np.sum((y_true == 0) & (y_pred == 1))\n",
        "    FN = np.sum((y_true == 1) & (y_pred == 0))\n",
        "\n",
        "    confusion_matrix = np.array([[TN, FP],\n",
        "                                  [FN, TP]])\n",
        "\n",
        "    precision = TP / (TP + FP) if (TP + FP) > 0 else 0.0\n",
        "    recall = TP / (TP + FN) if (TP + FN) > 0 else 0.0\n",
        "    f1_score = (2 * precision * recall) / (precision + recall) if (precision + recall) > 0 else 0.0\n",
        "\n",
        "    return {\n",
        "        \"confusion_matrix\": confusion_matrix,\n",
        "        \"precision\": precision,\n",
        "        \"recall\": recall,\n",
        "        \"f1_score\": f1_score\n",
        "    }"
      ],
      "metadata": {
        "id": "aqHa1MVCdkgr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}